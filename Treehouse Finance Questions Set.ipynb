{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treehouse Finance Problem Set\n",
    "\n",
    "### Author: Sowmya Uppili Raghavan\n",
    "### Date: 12th August 2021\n",
    "\n",
    "### 1.0 Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance (dependency for Yahoo Finance module)\n",
    "#!pip install fix_yahoo_finance\n",
    "#!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "# Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# Statistical calculation\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Data fetching from Yahoo Finance\n",
    "import fix_yahoo_finance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Answer\n",
    "\n",
    "**Question**:\n",
    "\n",
    "Give the name of employees, whose salaries are greater than their immediate manager’s.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "For this question, it requires the function to do the following set of steps:\n",
    "\n",
    "1. Sort the table by manager_id and salary to identify the hierarchies across manager ids.\n",
    "2. Fulfill Condition #1: Iterate through the rows of salary i.e. if the first row in the table has a lesser salary than the subsequent row;\n",
    "3. Fulfill Condition #2: Iterate through the rows of manager_id i.e. if the first row in the table has a greater manager_id than the subsequent manager_id;\n",
    "4. Append the value of the name for the index in which Conditions 1 & 2 are fulfilled.\n",
    "5. Exceptions: If manager_id is undefined or 'NA' in this scenario, we have two possibilities for this: a) either the manager id has been wrongly entered within the system, in which case we exclude the data, or b) we assume that the individual is not a manager and therefore below in the hierarchy.\n",
    "\n",
    "Using these conditions, the correct answer should be **Sally**, **Dan**, and assuming Phil with a manager_id = 'NULL' that he is a worker, **Phil**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   name  salary  manager_id\n",
      "2   3  Sally     550         4.0\n",
      "0   1   John     300         3.0\n",
      "1   2   Mike     200         3.0\n",
      "[]\n",
      "   id   name  salary  manager_id\n",
      "4   5    Joe     600         7.0\n",
      "3   4   Jane     500         7.0\n",
      "2   3  Sally     550         4.0\n",
      "0   1   John     300         3.0\n",
      "1   2   Mike     200         3.0\n",
      "['Sally']\n",
      "   id   name  salary  manager_id\n",
      "4   5    Joe     600         7.0\n",
      "3   4   Jane     500         7.0\n",
      "2   3  Sally     550         4.0\n",
      "5   6    Dan     600         3.0\n",
      "0   1   John     300         3.0\n",
      "1   2   Mike     200         3.0\n",
      "6   7   Phil     550         NaN\n",
      "['Sally', 'Dan', 'Phil']\n"
     ]
    }
   ],
   "source": [
    "#read the data \n",
    "data = pd.read_csv('question1_sample.csv')\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "def get_names(data):\n",
    "    data = data.sort_values([\"manager_id\", \"salary\"], ascending = False)\n",
    "    lst = []\n",
    "    for i in list(range(0, len(data)-2)):\n",
    "        if data.iloc[i]['salary'] < data.iloc[i+1]['salary'] and (data.iloc[i]['manager_id'] > data.iloc[i+1]['manager_id']):\n",
    "            lst.append(data.iloc[i+1]['name'])\n",
    "    if data.iloc[len(data)-1]['salary'] > data.iloc[len(data)-2]['salary']:\n",
    "        lst.append(data.iloc[len(data)-1]['name'])\n",
    "    return lst, data\n",
    "\n",
    "# Test Case #1: first three rows of data should return an empty list.\n",
    "lst, test_1 = get_names(data.head(3))\n",
    "print(test_1)\n",
    "print(lst)\n",
    "\n",
    "# Test Case #2: first five rows of data should return 'Sally'.\n",
    "lst2, test_2 = get_names(data.head(5))\n",
    "print(test_2)\n",
    "print(lst2)\n",
    "\n",
    "# Test Case #3: All rows of data should return 'Sally', 'Dan', 'Phil'.\n",
    "lst3, test_3 = get_names(data)\n",
    "print(test_3)\n",
    "print(lst3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Answer\n",
    "\n",
    "**Question**: What is the average salary of employees who do not manage anyone? In the sample\n",
    "above, that would be John, Mike, Joe and Dan, since they do not have anyone\n",
    "reporting to them.\n",
    "\n",
    "**Answer**: The process will work as follows:\n",
    "1. Find the minimum manager_id value within the table.\n",
    "2. Iterate through the rows of manager_id and if the manager_id is equal to the minimum value, add it to a sum variable.\n",
    "3. If the row meets the previous condition, add it to the counter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average salary of employees that do not manage anyone is: 366.6666666666667\n"
     ]
    }
   ],
   "source": [
    "def get_average(data):\n",
    "    lst2 = []\n",
    "    sume = 0 \n",
    "    counter = 0 \n",
    "    for i in list(range(0, len(data)-1)):\n",
    "        if data.iloc[i]['manager_id'] == data.manager_id.min():\n",
    "            sume += data.iloc[i]['salary']\n",
    "            counter += 1 \n",
    "    print(\"The average salary of employees that do not manage anyone is: \" + str(sume/counter))\n",
    "    \n",
    "get_average(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Answer\n",
    "\n",
    "**Question**: Write a function ‘exists’ which takes a variable symbol v and returns whether v is defined.\n",
    "\n",
    "**Answer**: There are multiple options for us to check if a variable symbol v is defined.\n",
    "\n",
    "1. Option #1: Using a simple if, else pattern, check if v is in the global scope, else if false check if variable v is in the local scope. Finally, if both return False return \"The variable is not defined.\"\n",
    "2. Option #2: To check if a variable v exists without running it, using the 'try' statement in Python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable is not defined.\n"
     ]
    }
   ],
   "source": [
    "## OPTION #1: Define if v exists in the local or global scope. \n",
    "\n",
    "def define(v):\n",
    "    if v in globals():\n",
    "        print(\"The variable exists and defined in a global scope.\")\n",
    "    elif v in locals():\n",
    "        print(\"The variable exists and defined in a local scope.\")\n",
    "    else:\n",
    "        print(\"The variable is not defined.\")\n",
    "\n",
    "        \n",
    "## OPTION #2: \n",
    "\n",
    "try:\n",
    "    v\n",
    "except NameError:\n",
    "    print(\"The variable is not defined.\")\n",
    "else:\n",
    "    print(\"The variable is defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Answer\n",
    "\n",
    "**Question**: Create a function to compute N layer of a Pascal Triangle.\n",
    "\n",
    "**Answer**: Let n be the number of layers in the pascal triangle, where the  the sum of values in the nth row is 2n.\n",
    "For i in the range of the n rows, print C where C = C * (i - j)/j, where j refers to i +1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "1 1 \n",
      "1 2 1 \n",
      "1 3 3 1 \n"
     ]
    }
   ],
   "source": [
    "def printPascal(n):\n",
    "    for i in range(1, n + 1):\n",
    "        C = 1; # used to represent C(i, j)\n",
    "        for i in range(1, i + 1):\n",
    "            print(C, end = \" \")\n",
    "            C = int(C * (i - j) / j)\n",
    "        print(\"\")\n",
    "#test code \n",
    "n = 4;\n",
    "printPascal(n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4(a) Answer\n",
    "\n",
    "**Question**: Using historical daily returns (Yahoo/Google Finance or any other market data\n",
    "source), calculate VaR95% and CVaR95% of the portfolio as of 2016/12/31.\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "The **Historical value at risk (VaR)**, also known as historical simulation or the historical method, refers to a particular way of calculating VaR. In this approach we calculate VaR directly from past returns.\n",
    "\n",
    "1. We pull data defined by the tickers and weights assigned in the portfolio for the 'Close' positions for each ticker.\n",
    "2. Define start date as 2016/01/01 and end date as 2016/12/31 respectively.\n",
    "3. In the get_historicVaR function, assign a historical_returns variable which returns the cumulative sum of all returns by weight for the time period.\n",
    "3. **Historical VaR**: Return the 95th Percentile of these historical returns using the numpy percentile function.\n",
    "3. **Conditional VaR**: Return the average value of  historical returns exceeding Historical VaR. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historic 95% VaR of Portfolio is:-0.014168767474557241\n",
      "Historic 95% CVaR of Portfolio is:-0.021256080522287904\n"
     ]
    }
   ],
   "source": [
    "# Create our portfolio of equities\n",
    "tickers = ['AAPL','IBM', 'GOOG', 'BP', 'XOM', 'COST', 'GS']\n",
    "weights = np.array([.15, .20, .20, .15, 0.10, 0.15, 0.05])\n",
    "\n",
    "def get_data(tickers, weights):\n",
    "    data = pdr.get_data_yahoo(tickers, start=\"2016-01-01\", end='2016-12-31')['Close']\n",
    "    returns = data.pct_change()\n",
    "    returns = returns.dropna()\n",
    "    return returns\n",
    "\n",
    "def get_historicVaR(tickers,weights):\n",
    "    returns = get_data(tickers,weights)\n",
    "    historical_returns = (weights * returns.values).sum(axis=1)\n",
    "    historic_VaR95 = np.percentile(historical_returns, 5)\n",
    "    cvar_95 = historical_returns[historical_returns <= historic_VaR95].mean()\n",
    "    print(\"Historic 95% VaR of Portfolio is:\"+str(historic_VaR95))\n",
    "    print(\"Historic 95% CVaR of Portfolio is:\"+str(cvar_95))\n",
    "\n",
    "get_historicVaR(tickers,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4(b) Answer \n",
    "\n",
    "**Question**: Using expected mean, covariance matrix and parametric method, calculate VaR95%\n",
    "and CVaR95%\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "VaR modeling determines the potential for loss in the entity being assessed and the probability of occurrence for the defined loss. Instead of relying on historical daily returns, the Parametric VaR method calculates the VaR based on a  probability density function which inputs the standard deviation, the mean and the confidence level of the portfolio. \n",
    "\n",
    "i. Calculating **Parametric Value at Risk (95%VaR)**:\n",
    "1. Generate Var-Cov Matrix\n",
    "2. Calculate Mean Returns ofr Each Stuck\n",
    "3. Calculate mean Returns for Portfolio\n",
    "3. Calculate Portfolio Std. Dev.\n",
    "5. Determine Confidence Level - 0.95%\n",
    "\n",
    "ii. The **Parametric Conditional Value at Risk (CVaR**, or expected shortfall (ES), asks what the average loss will be, conditional upon losses exceeding some threshold at a certain confidence level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametric 95% VaR of Portfolio is:-0.01441002502874713\n",
      "Parametric 95% CVaR of Portfolio is:0.02885832242185969\n"
     ]
    }
   ],
   "source": [
    "def get_parametricVar(tickers, weights, confidence_level=0.05):\n",
    "    returns = get_data(tickers, weights)\n",
    "    cov_matrix = returns.cov()\n",
    "    avg_returns = returns.mean()\n",
    "    port_mean = avg_returns@weights\n",
    "    port_stdev = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "    x = np.arange(-0.05, 0.05, 0.001)\n",
    "    norm_dist = norm.pdf(x, port_mean, port_stdev)\n",
    "    parametric_VaR95 = norm.ppf(confidence_level, port_mean, port_stdev)\n",
    "    tail_loss = norm.expect(lambda x: x, loc = port_mean, scale = port_stdev, lb = parametric_VaR95)\n",
    "    parametric_CVaR_95 = (1 / (1 - 0.95)) * tail_loss\n",
    "    print(\"Parametric 95% VaR of Portfolio is: \"+str(parametric_VaR95))\n",
    "    print(\"Parametric 95% CVaR of Portfolio is: \"+str(parametric_CVaR_95))\n",
    "\n",
    "\n",
    "get_parametricVar(tickers, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4(c) Answer \n",
    "\n",
    "**Answer**:\n",
    "    \n",
    "Understanding that there is a risk-return trade-off, a portfolio optimization strategy for each month would contain the following:\n",
    "\n",
    "1. Using the covariance matrix above, it is apparent that the risk in the portfolio is not equivalent to the weighted average of individual stocks in the portfolio.\n",
    "2. Instead, the risk is around volatitility, defined as the relationship of stock movement with each other. \n",
    "3. The Sharpe Ratio identifies the highest risk-free return across a permutation of all different weighted portfolios. Essentially, it identifies *i* in *n* number of portfolios with the highest return, *r*, given the lowest relative risk, *j*.\n",
    "4. For each month, I would get the average returns and the covariance matrix as seen in the first helper function. \n",
    "5. Using the Scipy minimization function, I would calculate the max sharp_ratio for a portfolio in a given month using an adjusted monthly risk rate (defined as the monthly average of the risk rate provided by the U.S. treasury in the year 2015-2016). \n",
    "6. For that given month, I would assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_monthly_returns(stock, ticker):\n",
    "    data = pdr.get_data_yahoo(tickers, start=\"2016-01-01\", end='2016-12-31')['Close']\n",
    "    returns = data.pct_change()\n",
    "    returns = returns.dropna()\n",
    "    returns = returns.reset_index()\n",
    "    returns['Date'] = pd.to_datetime(returns['Date'])\n",
    "    returns['Month'] = returns['Date'].dt.month\n",
    "\n",
    "def max_sharpe_ratio(stock, ticker, risk_free_rate=0.18):\n",
    "    returns = get_monthly_returns(stock, ticker)\n",
    "    cov_matrix = returns.cov()\n",
    "    avg_returns = returns.mean()\n",
    "    num_assets = len(avg_returns)\n",
    "    args = (mean_returns, cov_matrix, risk_free_rate)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0,1.0)\n",
    "    bounds = tuple(bound for asset in range(num_assets))\n",
    "    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n",
    "                        method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5(a) Answer\n",
    "\n",
    "**Question**: How many python files in the directory?\n",
    "\n",
    "**Answer**: Using the git function on the command line, pattern match and aggregate the numnber of files with the \".py\" suffix.\n",
    "\n",
    "```\n",
    "git ls-files | grep \"\\.py$\" | wc -l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5(b) Answer\n",
    "\n",
    "**Question**: How many lines of code in total, how many lines of comment line (empty line doesn’t\n",
    "count)\n",
    "\n",
    "**Answer**: Using svn, a custom command analogous to git, the \n",
    "\n",
    "```\n",
    "!pip install svn\n",
    "!svn ls -R https://github.com/“my-python-project”/branches/master | wc -l\n",
    "```\n",
    "\n",
    "\n",
    "## 5(c) Answer\n",
    "\n",
    "**Question**: How many functions is defined in total?\n",
    "\n",
    "**Answer**: The first step is to define the Github directory in your local path. The second step is to apply a function that locates the number of functions per file extension defined by the user.\n",
    "\n",
    "```\n",
    "\n",
    "import inspect\n",
    "import importlib\n",
    "import ast\n",
    "import glob\n",
    "\n",
    "\n",
    "files = glob.glob(\"/Users/Github/my-python-project\" + '/**/*.py', recursive=True)\n",
    "\n",
    "class CountFunc(ast.NodeVisitor):\n",
    "    func_count = 0\n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.func_count += 1\n",
    "\n",
    "\n",
    "functions_count = []\n",
    "\n",
    "for _file in files:\n",
    "  p = ast.parse(open(_file).read())\n",
    "  f = CountFunc()\n",
    "  f.visit(p)\n",
    "  functions_count.append(f.func_count)\n",
    "  \n",
    "\n",
    "print (f'Number of functions are {sum(functions_count)}')\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5(d) Answer\n",
    "\n",
    "**Question**: How many lines of changes from the current version against HEAD~3?\n",
    "\n",
    "**Answer**: Using the git function on the command line, pattern match and aggregate the numnber of files with the \".py\" suffix.\n",
    "\n",
    "```\n",
    "!git diff --stat HEAD-3 HEAD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Answer \n",
    "\n",
    "**Question**: In a text file, give me total number of appearance of “date” within the text file The date\n",
    "format can appears in either one (or multiple) formats shown below:\n",
    "    \n",
    "**Answer**: Using regex pattern matching, match the following patterns:\n",
    "\n",
    "1. DD/MM/YYYY: This has two digits with a max of 1 and 2 respectively, followed by two digits with a max of 3 and 1 for both digits respectively, and finally a final set of four digits with a / delimiter. \n",
    "2. MM/DD/YYYY: Similar ot the above pattern, this has two digits with a max of 3 and 1 followed by two digits with a max of 1 and 2, and a final set of four digits with a delimiter. \n",
    "3. DD/Jan/Feb/March/Dec/YYYY: Similar ot the above pattern, this has two digits with a max of 1 and 2 followed by four letters, and a final set of four digits with a delimiter. \n",
    "\n",
    "If any word in the text file matches the above patterns, add to a list and return the length of the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#f = open(\"demofile.txt\", \"r\")\n",
    "\n",
    "text = '10/2020/10, 10/10/2020, 2020/01/02, 01/Aug/2020'\n",
    "\n",
    "def get_count(text):\n",
    "    # Finds MM/DD/YYY and DD/MM/YYY\n",
    "    pattern = \"\\d{2}[/-]\\d{2}[/-]\\d{4}\"\n",
    "    #Finds YYYY/MM/DD\n",
    "    pattern2 = \"\\d{4}[/-]\\d{2}[/-]\\d{2}\"\n",
    "    ## Finds DD/Jan/Aug/Dec/etc../YYYY\n",
    "    pattern3 = \"\\d{2}[/-][a-zA-Z]+[/-]\\d{4}\"\n",
    "    #Create a pattern list\n",
    "    pattern_lst = [pattern, pattern2, pattern3]\n",
    "    found_regex_list = []\n",
    "    for x in pattern_lst:\n",
    "        if re.findall(x, text):\n",
    "            some_list = re.findall(x, text)     \n",
    "        for y in some_list:\n",
    "            found_regex_list.append(y)\n",
    "    print(len(found_regex_list))\n",
    "\n",
    "get_count(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
